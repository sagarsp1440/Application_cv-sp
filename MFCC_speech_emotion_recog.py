# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ks7HnwEBMfPEYO4afXQyo1_p3oN_r8SJ
"""

from google.colab import drive
drive.mount('/content/drive')

pip install pydub

import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import IPython.display as ipd
from pydub import AudioSegment
from pydub.utils import mediainfo
speech = AudioSegment.from_wav('arctic_a0005.wav') 
x = speech.get_array_of_samples() 
x_sr = speech.frame_rate 
mfcc = librosa.feature.mfcc(
np.float32(x),
sr = x_sr, 
hop_length = int(x_sr * 0.015), 
n_mfcc = 12 
)

mfcc.shape

mfcc_flattened = np.reshape(mfcc.T, (mfcc.shape[0] * mfcc.shape[1]))
plt.figure(figsize = (15, 5))
plt.plot(mfcc_flattened)
plt.ylabel('Amplitude')

import os
emotions = ['Angry','Calm', 'Happy', 'Sad']
path = '/content/drive/My Drive/EmotionSpeech/'
training_file_names = []
training_emotion_labels = []
for i in range(0, len(emotions)):
  sub_path = path + 'Train/' + emotions[i] + '/'
  sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]
  sub_emotion_labels = [i] * len(sub_file_names)
  training_file_names += sub_file_names
  training_emotion_labels += sub_emotion_labels

test_file_names = []
test_emotion_labels = []
for i in range(0, len(emotions)):
  sub_path = path + 'Test/' + emotions[i] + '/'
  sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]
  sub_emotion_labels = [i] * len(sub_file_names)
  test_file_names += sub_file_names
  test_emotion_labels += sub_emotion_labels

import numpy as np
import librosa
from pydub import AudioSegment
from pydub.utils import mediainfo
def mfcc_extraction(audio_filename, hop_duration,num_mfcc,num_frames):
  speech = AudioSegment.from_wav(audio_filename) #Read audio data from file
  samples = speech.get_array_of_samples() #samples x(t)
  sampling_rate = speech.frame_rate #sampling rate f - see slide 24 in week 7 lecture slides
  mfcc = librosa.feature.mfcc(np.float32(samples),sr = sampling_rate,hop_length = int(sampling_rate * hop_duration),n_mfcc = num_mfcc)
  mfcc_truncated = np.zeros((num_mfcc, num_frames), np.float32)
  for i in range(min(num_frames, mfcc.shape[1])):
    mfcc_truncated[:, i] = mfcc[:, i]
  return np.reshape(mfcc_truncated.T, mfcc_truncated.shape[0] * mfcc_truncated.shape[1])

hop_duration = 0.015
num_mfcc =[12,14,16,18,20,22,24,26,28,30]
num_frames = 200

from sklearn import svm
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report, confusion_matrix

train_mfcc = []
test_mfcc = []
for i in num_mfcc:
  train_mfcc = []
  test_mfcc = []
  for filename in training_file_names:
    train_mfcc.append(mfcc_extraction(filename, hop_duration, i,num_frames))
    
  for filename in test_file_names:
    test_mfcc.append(mfcc_extraction(filename, hop_duration,i,num_frames))

  svm_1=svm.SVC()
  svm_1.fit(train_mfcc,training_emotion_labels)

  pred_labels = svm_1.predict(test_mfcc)
  print('SVM for num_mfcc : ', i)
  print('report:', np.sum(pred_labels ==test_emotion_labels)/len(test_emotion_labels))
  print('confusion matrix: \n',confusion_matrix(test_emotion_labels,pred_labels))

  ada= AdaBoostClassifier()
  ada.fit(train_mfcc,training_emotion_labels)

  pred_labels1 = ada.predict(test_mfcc)
  print('AdaBoost for num_mfcc : ', i)
  print('report:', np.sum(pred_labels1 ==test_emotion_labels)/len(test_emotion_labels))
  print('confusion matrix: \n',confusion_matrix(test_emotion_labels,pred_labels1))















pred_labels = ada.predict(test_mfcc)
print('report:', np.sum(pred_labels ==test_emotion_labels)/len(test_emotion_labels))
print('confusion matrix: \n',confusion_matrix(test_emotion_labels,pred_labels))

